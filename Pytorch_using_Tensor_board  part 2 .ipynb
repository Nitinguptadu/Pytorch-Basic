{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pdb\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True) \n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "0.3.0\n",
      "1.15.0a20190806\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "import tensorboard\n",
    "print(tensorboard.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 26320896/26421880 [00:22<00:00, 1498107.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/29515 [00:00<?, ?it/s]\u001b[A\n",
      " 56%|█████▌    | 16384/29515 [00:00<00:00, 80806.23it/s]\u001b[A\n",
      "32768it [00:00, 33411.44it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4422102 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/4422102 [00:00<01:11, 61224.39it/s]\u001b[A\n",
      "  1%|          | 40960/4422102 [00:00<00:58, 74443.14it/s]\u001b[A\n",
      "  1%|          | 49152/4422102 [00:01<01:14, 58878.17it/s]\u001b[A\n",
      "  2%|▏         | 98304/4422102 [00:01<00:55, 78505.61it/s]\u001b[A\n",
      "  3%|▎         | 131072/4422102 [00:01<00:46, 93215.94it/s]\u001b[A\n",
      "  4%|▎         | 155648/4422102 [00:01<00:39, 106886.89it/s]\u001b[A\n",
      "  4%|▍         | 188416/4422102 [00:01<00:35, 118330.98it/s]\u001b[A\n",
      "  5%|▌         | 221184/4422102 [00:02<00:31, 132704.84it/s]\u001b[A\n",
      "  6%|▌         | 253952/4422102 [00:02<00:27, 151585.95it/s]\u001b[A\n",
      "  6%|▋         | 286720/4422102 [00:02<00:25, 160324.38it/s]\u001b[A\n",
      "  7%|▋         | 319488/4422102 [00:02<00:22, 183496.37it/s]\u001b[A\n",
      "  8%|▊         | 344064/4422102 [00:02<00:22, 180633.32it/s]\u001b[A\n",
      "  8%|▊         | 368640/4422102 [00:02<00:22, 179074.75it/s]\u001b[A\n",
      "  9%|▉         | 401408/4422102 [00:02<00:20, 195237.04it/s]\u001b[A\n",
      " 10%|▉         | 425984/4422102 [00:03<00:19, 202077.01it/s]\u001b[A\n",
      " 10%|█         | 450560/4422102 [00:03<00:20, 195432.29it/s]\u001b[A\n",
      " 11%|█         | 483328/4422102 [00:03<00:19, 205304.62it/s]\u001b[A\n",
      " 12%|█▏        | 516096/4422102 [00:03<00:18, 213318.42it/s]\u001b[A\n",
      " 12%|█▏        | 540672/4422102 [00:03<00:18, 213070.87it/s]\u001b[A\n",
      " 13%|█▎        | 565248/4422102 [00:03<00:18, 209416.91it/s]\u001b[A\n",
      " 14%|█▎        | 598016/4422102 [00:03<00:18, 210899.86it/s]\u001b[A\n",
      " 14%|█▍        | 630784/4422102 [00:03<00:16, 223495.56it/s]\u001b[A\n",
      " 15%|█▍        | 655360/4422102 [00:04<00:17, 214890.15it/s]\u001b[A\n",
      " 15%|█▌        | 679936/4422102 [00:04<00:17, 210238.48it/s]\u001b[A\n",
      " 16%|█▌        | 712704/4422102 [00:04<00:17, 216908.48it/s]\u001b[A\n",
      " 17%|█▋        | 737280/4422102 [00:04<00:16, 218341.12it/s]\u001b[A\n",
      " 17%|█▋        | 761856/4422102 [00:04<00:16, 221210.39it/s]\u001b[A\n",
      " 18%|█▊        | 794624/4422102 [00:04<00:16, 215047.59it/s]\u001b[A\n",
      " 19%|█▊        | 827392/4422102 [00:04<00:16, 222303.19it/s]\u001b[A\n",
      " 19%|█▉        | 851968/4422102 [00:04<00:16, 216774.18it/s]\u001b[A\n",
      " 20%|█▉        | 876544/4422102 [00:05<00:15, 222169.05it/s]\u001b[A\n",
      " 20%|██        | 901120/4422102 [00:05<00:16, 219913.47it/s]\u001b[A\n",
      " 21%|██        | 925696/4422102 [00:05<00:15, 219726.18it/s]\u001b[A\n",
      " 21%|██▏       | 950272/4422102 [00:05<00:15, 221412.92it/s]\u001b[A\n",
      " 22%|██▏       | 974848/4422102 [00:05<00:15, 228092.21it/s]\u001b[A\n",
      " 23%|██▎       | 999424/4422102 [00:05<00:16, 207072.35it/s]\u001b[A\n",
      " 23%|██▎       | 1024000/4422102 [00:05<00:17, 198573.72it/s]\u001b[A\n",
      " 24%|██▍       | 1064960/4422102 [00:05<00:16, 206236.94it/s]\u001b[A\n",
      " 25%|██▌       | 1105920/4422102 [00:06<00:14, 231157.06it/s]\u001b[A\n",
      " 26%|██▌       | 1138688/4422102 [00:06<00:13, 236217.83it/s]\u001b[A\n",
      " 26%|██▋       | 1163264/4422102 [00:06<00:14, 222651.53it/s]\u001b[A\n",
      " 27%|██▋       | 1196032/4422102 [00:06<00:15, 214536.86it/s]\u001b[A\n",
      " 28%|██▊       | 1236992/4422102 [00:06<00:13, 237959.67it/s]\u001b[A\n",
      " 29%|██▉       | 1277952/4422102 [00:06<00:12, 254591.79it/s]\u001b[A\n",
      " 30%|██▉       | 1310720/4422102 [00:06<00:12, 253351.61it/s]\u001b[A\n",
      " 30%|███       | 1343488/4422102 [00:07<00:12, 243476.70it/s]\u001b[A\n",
      " 31%|███▏      | 1384448/4422102 [00:07<00:11, 261809.95it/s]\u001b[A\n",
      " 32%|███▏      | 1417216/4422102 [00:07<00:11, 272695.43it/s]\u001b[A\n",
      " 33%|███▎      | 1449984/4422102 [00:07<00:11, 258624.85it/s]\u001b[A\n",
      " 34%|███▍      | 1499136/4422102 [00:07<00:10, 267836.36it/s]\u001b[A\n",
      " 35%|███▍      | 1531904/4422102 [00:07<00:10, 279178.95it/s]\u001b[A\n",
      " 36%|███▌      | 1572864/4422102 [00:07<00:09, 288182.85it/s]\u001b[A\n",
      " 37%|███▋      | 1622016/4422102 [00:08<00:09, 299615.31it/s]\u001b[A\n",
      " 38%|███▊      | 1662976/4422102 [00:08<00:08, 318375.01it/s]\u001b[A\n",
      " 39%|███▊      | 1703936/4422102 [00:08<00:08, 317844.38it/s]\u001b[A\n",
      " 40%|███▉      | 1761280/4422102 [00:08<00:07, 346239.87it/s]\u001b[A\n",
      " 41%|████      | 1802240/4422102 [00:08<00:07, 354342.45it/s]\u001b[A\n",
      " 42%|████▏     | 1851392/4422102 [00:08<00:06, 373093.72it/s]\u001b[A\n",
      " 43%|████▎     | 1908736/4422102 [00:08<00:06, 392487.92it/s]\u001b[A\n",
      " 44%|████▍     | 1957888/4422102 [00:08<00:06, 403995.29it/s]\u001b[A\n",
      " 45%|████▌     | 2007040/4422102 [00:08<00:05, 420251.23it/s]\u001b[A\n",
      " 47%|████▋     | 2072576/4422102 [00:09<00:05, 466953.02it/s]\u001b[A\n",
      " 48%|████▊     | 2121728/4422102 [00:09<00:05, 449901.15it/s]\u001b[A\n",
      " 49%|████▉     | 2187264/4422102 [00:09<00:04, 483952.07it/s]\u001b[A\n",
      " 51%|█████     | 2252800/4422102 [00:09<00:04, 515786.75it/s]\u001b[A\n",
      " 52%|█████▏    | 2310144/4422102 [00:09<00:04, 502543.77it/s]\u001b[A\n",
      " 54%|█████▎    | 2375680/4422102 [00:09<00:03, 540125.33it/s]\u001b[A\n",
      " 55%|█████▌    | 2441216/4422102 [00:09<00:03, 566294.87it/s]\u001b[A\n",
      " 57%|█████▋    | 2514944/4422102 [00:09<00:03, 607939.17it/s]\u001b[A\n",
      " 58%|█████▊    | 2580480/4422102 [00:09<00:02, 617811.67it/s]\u001b[A\n",
      " 60%|██████    | 2662400/4422102 [00:10<00:02, 643721.89it/s]\u001b[A\n",
      " 62%|██████▏   | 2736128/4422102 [00:10<00:02, 640587.22it/s]\u001b[A\n",
      " 64%|██████▍   | 2834432/4422102 [00:10<00:02, 685770.23it/s]\u001b[A\n",
      " 66%|██████▌   | 2924544/4422102 [00:10<00:02, 728670.21it/s]\u001b[A\n",
      " 68%|██████▊   | 3006464/4422102 [00:10<00:01, 729526.69it/s]\u001b[A\n",
      " 70%|███████   | 3104768/4422102 [00:10<00:01, 785323.34it/s]\u001b[A\n",
      " 72%|███████▏  | 3186688/4422102 [00:10<00:01, 787397.35it/s]\u001b[A\n",
      " 74%|███████▍  | 3268608/4422102 [00:10<00:01, 791495.85it/s]\u001b[A\n",
      " 76%|███████▌  | 3366912/4422102 [00:10<00:01, 816756.45it/s]\u001b[A\n",
      " 78%|███████▊  | 3457024/4422102 [00:11<00:01, 832529.18it/s]\u001b[A\n",
      " 81%|████████  | 3579904/4422102 [00:11<00:00, 914680.62it/s]\u001b[A\n",
      " 83%|████████▎ | 3678208/4422102 [00:11<00:00, 906644.62it/s]\u001b[A\n",
      " 86%|████████▌ | 3801088/4422102 [00:11<00:00, 979191.01it/s]\u001b[A\n",
      " 88%|████████▊ | 3907584/4422102 [00:11<00:00, 1001189.27it/s]\u001b[A\n",
      " 91%|█████████ | 4030464/4422102 [00:11<00:00, 1059722.79it/s]\u001b[A\n",
      " 94%|█████████▎| 4145152/4422102 [00:11<00:00, 1054723.14it/s]\u001b[A\n",
      " 96%|█████████▋| 4259840/4422102 [00:11<00:00, 1079090.28it/s]\u001b[A\n",
      " 99%|█████████▉| 4382720/4422102 [00:11<00:00, 1118048.13it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 8878.35it/s]             \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels =1,out_channels =6,kernel_size =5)\n",
    "        self.conv2 = nn.Conv2d(in_channels =6,out_channels =12,kernel_size =5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features= 60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "    # (1) input layer\n",
    "        t = t\n",
    "\n",
    "    # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "    # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "    # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "    # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "    # (6) output layer\n",
    "        t = self.out(t)\n",
    "    #t = F.softmax(t, dim=1)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [100, 1000, 10000]\n",
    "lr_list = [.01, .001, .0001, .00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46987 loss: 34041.04263037443\n",
      "epoch 1 total_correct: 51378 loss: 23214.93953168392\n",
      "epoch 2 total_correct: 52148 loss: 21314.07442688942\n",
      "epoch 3 total_correct: 52505 loss: 20210.12680530548\n",
      "epoch 4 total_correct: 52736 loss: 19449.157167971134\n",
      "epoch 0 total_correct: 41987 loss: 47551.70609652996\n",
      "epoch 1 total_correct: 48031 loss: 31881.6658526659\n",
      "epoch 2 total_correct: 50041 loss: 27291.413055360317\n",
      "epoch 3 total_correct: 51086 loss: 24515.468499064445\n",
      "epoch 4 total_correct: 51664 loss: 22735.7948243618\n",
      "epoch 0 total_correct: 32599 loss: 82135.21357774734\n",
      "epoch 1 total_correct: 42017 loss: 48130.21501302719\n",
      "epoch 2 total_correct: 44047 loss: 42532.71555900574\n",
      "epoch 3 total_correct: 45199 loss: 39239.95760381222\n",
      "epoch 4 total_correct: 46034 loss: 37074.31071102619\n",
      "epoch 0 total_correct: 6656 loss: 137512.50383853912\n",
      "epoch 1 total_correct: 25521 loss: 128613.3858203888\n",
      "epoch 2 total_correct: 31065 loss: 102370.87032794952\n",
      "epoch 3 total_correct: 37120 loss: 78893.59263181686\n",
      "epoch 4 total_correct: 39596 loss: 66912.55785226822\n",
      "epoch 0 total_correct: 34806 loss: 65779.09392118454\n",
      "epoch 1 total_correct: 47418 loss: 32396.999567747116\n",
      "epoch 2 total_correct: 49753 loss: 27079.607248306274\n",
      "epoch 3 total_correct: 51128 loss: 24002.636164426804\n",
      "epoch 4 total_correct: 51885 loss: 21908.626466989517\n",
      "epoch 0 total_correct: 25814 loss: 97159.60282087326\n",
      "epoch 1 total_correct: 42437 loss: 45039.17235136032\n",
      "epoch 2 total_correct: 44723 loss: 38688.491225242615\n",
      "epoch 3 total_correct: 45955 loss: 35452.85224914551\n",
      "epoch 4 total_correct: 46880 loss: 33276.870399713516\n",
      "epoch 0 total_correct: 8221 loss: 137452.67724990845\n",
      "epoch 1 total_correct: 19232 loss: 130275.17509460449\n",
      "epoch 2 total_correct: 30692 loss: 100028.73516082764\n",
      "epoch 3 total_correct: 37177 loss: 68820.81234455109\n",
      "epoch 4 total_correct: 39273 loss: 58173.30223321915\n",
      "epoch 0 total_correct: 6000 loss: 138332.9997062683\n",
      "epoch 1 total_correct: 6000 loss: 138217.41771697998\n",
      "epoch 2 total_correct: 6000 loss: 138051.6905784607\n",
      "epoch 3 total_correct: 6000 loss: 137821.66123390198\n",
      "epoch 4 total_correct: 6000 loss: 137527.4395942688\n",
      "epoch 0 total_correct: 13848 loss: 128770.03312110901\n",
      "epoch 1 total_correct: 28806 loss: 81790.56882858276\n",
      "epoch 2 total_correct: 37470 loss: 58510.56933403015\n",
      "epoch 3 total_correct: 41692 loss: 48250.16260147095\n",
      "epoch 4 total_correct: 43044 loss: 43679.401874542236\n",
      "epoch 0 total_correct: 10266 loss: 137670.87697982788\n",
      "epoch 1 total_correct: 21974 loss: 135150.71153640747\n",
      "epoch 2 total_correct: 25267 loss: 128212.3613357544\n",
      "epoch 3 total_correct: 29717 loss: 112089.78652954102\n",
      "epoch 4 total_correct: 31875 loss: 88208.16993713379\n",
      "epoch 0 total_correct: 6002 loss: 138195.4002380371\n",
      "epoch 1 total_correct: 6011 loss: 138022.49670028687\n",
      "epoch 2 total_correct: 6095 loss: 137843.01280975342\n",
      "epoch 3 total_correct: 6258 loss: 137636.50178909302\n",
      "epoch 4 total_correct: 6655 loss: 137390.1629447937\n",
      "epoch 0 total_correct: 5999 loss: 138385.13612747192\n",
      "epoch 1 total_correct: 5999 loss: 138366.1699295044\n",
      "epoch 2 total_correct: 5999 loss: 138347.25618362427\n",
      "epoch 3 total_correct: 5999 loss: 138328.3805847168\n",
      "epoch 4 total_correct: 5998 loss: 138309.81254577637\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = Network()\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "        optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "        images, labels = next(iter(train_loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        comment=f' batch_size={batch_size} lr={lr}'\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        tb.add_image('images', grid)\n",
    "        tb.add_graph(network, images)\n",
    "\n",
    "        for epoch in range(5):\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "            for batch in train_loader:\n",
    "                images, labels = batch # Get Batch\n",
    "                preds = network(images) # Pass Batch\n",
    "                loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "                optimizer.zero_grad() # Zero Gradients\n",
    "                loss.backward() # Calculate Gradients\n",
    "                optimizer.step() # Update Weights\n",
    "\n",
    "                total_loss += loss.item() * batch_size\n",
    "                total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "            tb.add_scalar('Loss', total_loss, epoch)\n",
    "            tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "            tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "            for name, param in network.named_parameters():\n",
    "                tb.add_histogram(name, param, epoch)\n",
    "                tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "            print(\n",
    "                \"epoch\", epoch\n",
    "                ,\"total_correct:\", total_correct\n",
    "                ,\"loss:\", total_loss\n",
    "            )  \n",
    "        tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
